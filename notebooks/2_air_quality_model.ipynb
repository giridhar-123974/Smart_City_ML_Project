{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341f0d1f",
   "metadata": {},
   "source": [
    "# Air Quality Prediction Model\n",
    "\n",
    "Train a machine learning model to predict Air Quality Index (AQI) using sensor data.\n",
    "\n",
    "**Model**: Random Forest Regressor\n",
    "**Features**: 10 sensor readings\n",
    "**Target**: Air Quality Index (0-300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50225d62",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print('âœ“ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e3669",
   "metadata": {},
   "source": [
    "## 2. Create Synthetic Air Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f15c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic air quality data\n",
    "n_samples = 1000\n",
    "\n",
    "# Create features: 10 sensor readings\n",
    "data = {\n",
    "    'sensor_1': np.random.uniform(10, 50, n_samples),  # PM2.5\n",
    "    'sensor_2': np.random.uniform(20, 100, n_samples),  # PM10\n",
    "    'sensor_3': np.random.uniform(0, 50, n_samples),   # NO2\n",
    "    'sensor_4': np.random.uniform(0, 40, n_samples),   # SO2\n",
    "    'sensor_5': np.random.uniform(0, 30, n_samples),   # CO\n",
    "    'sensor_6': np.random.uniform(0, 100, n_samples),  # O3\n",
    "    'sensor_7': np.random.uniform(30, 80, n_samples),  # Humidity\n",
    "    'sensor_8': np.random.uniform(0, 40, n_samples),   # Temperature\n",
    "    'sensor_9': np.random.uniform(900, 1050, n_samples),  # Pressure\n",
    "    'sensor_10': np.random.uniform(0, 20, n_samples),  # Wind Speed\n",
    "}\n",
    "\n",
    "# Create AQI based on sensor values (simplified calculation)\n",
    "aqi = (data['sensor_1'] * 1.2 + \n",
    "       data['sensor_2'] * 0.8 + \n",
    "       data['sensor_3'] * 0.6 +\n",
    "       data['sensor_4'] * 0.5 -\n",
    "       data['sensor_7'] * 0.3 +\n",
    "       data['sensor_8'] * 0.2)\n",
    "\n",
    "aqi = np.clip(aqi, 0, 300) + np.random.normal(0, 5, n_samples)\n",
    "\n",
    "data['AQI'] = np.maximum(aqi, 0)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'\\nFirst 5 rows:')\n",
    "print(df.head())\n",
    "print(f'\\nDataset info:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef19f0",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing values:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('AQI', axis=1)  # Features (10 sensors)\n",
    "y = df['AQI']  # Target (AQI)\n",
    "\n",
    "# Split into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'\\nTraining set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n",
    "print(f'\\nFeatures: {X_train.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e0649",
   "metadata": {},
   "source": [
    "## 4. Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5597ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Random Forest Regressor\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('Training model...')\n",
    "model.fit(X_train, y_train)\n",
    "print('âœ“ Model training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256210c",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('='*50)\n",
    "print('MODEL EVALUATION METRICS')\n",
    "print('='*50)\n",
    "print(f'\\nTraining Set:')\n",
    "print(f'  RMSE: {train_rmse:.4f}')\n",
    "print(f'  MAE:  {train_mae:.4f}')\n",
    "print(f'  RÂ²:   {train_r2:.4f}')\n",
    "print(f'\\nTest Set:')\n",
    "print(f'  RMSE: {test_rmse:.4f}')\n",
    "print(f'  MAE:  {test_mae:.4f}')\n",
    "print(f'  RÂ²:   {test_r2:.4f}')\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6432d",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16226fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print('\\nFeature Importance:')\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance - Air Quality Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92c101",
   "metadata": {},
   "source": [
    "## 7. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500740fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/air_quality_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Save feature names for later use\n",
    "features_path = '../models/air_quality_features.pkl'\n",
    "joblib.dump(X_train.columns.tolist(), features_path)\n",
    "\n",
    "print(f'âœ“ Model saved to {model_path}')\n",
    "print(f'âœ“ Features saved to {features_path}')\n",
    "print(f'\\nModel file size: {os.path.getsize(model_path) / 1024:.2f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9170704",
   "metadata": {},
   "source": [
    "## 8. Test Predictions with Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247127ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample input data for testing\n",
    "sample_data = pd.DataFrame({\n",
    "    'sensor_1': [35],   # PM2.5\n",
    "    'sensor_2': [60],   # PM10\n",
    "    'sensor_3': [20],   # NO2\n",
    "    'sensor_4': [15],   # SO2\n",
    "    'sensor_5': [10],   # CO\n",
    "    'sensor_6': [50],   # O3\n",
    "    'sensor_7': [55],   # Humidity\n",
    "    'sensor_8': [25],   # Temperature\n",
    "    'sensor_9': [1013], # Pressure\n",
    "    'sensor_10': [5],   # Wind Speed\n",
    "})\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(sample_data)[0]\n",
    "\n",
    "print('Sample Input Data:')\n",
    "print(sample_data)\n",
    "print(f'\\nPredicted AQI: {prediction:.2f}')\n",
    "\n",
    "# Interpret AQI\n",
    "if prediction <= 50:\n",
    "    quality = 'ðŸŸ¢ Good'\n",
    "elif prediction <= 100:\n",
    "    quality = 'ðŸŸ¡ Moderate'\n",
    "elif prediction <= 150:\n",
    "    quality = 'ðŸŸ  Unhealthy for Sensitive Groups'\n",
    "elif prediction <= 200:\n",
    "    quality = 'ðŸ”´ Unhealthy'\n",
    "else:\n",
    "    quality = 'âš« Very Unhealthy'\n",
    "\n",
    "print(f'Air Quality Status: {quality}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
